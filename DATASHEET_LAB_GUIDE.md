# Datasheet AI Test Bench - Complete Guide

## ðŸŽ¯ Overview

The **Datasheet AI Test Bench** is a standalone testing playground for the datasheet parsing and Q&A features. It provides a dedicated environment for engineers to upload datasheets, test AI queries, and validate the anti-hallucination mechanisms without affecting production workflows.

## ðŸ“ Access

Navigate to: **`/datasheet-lab`**

Or click **"Datasheet AI Lab"** in the sidebar navigation (marked with a "Lab" badge).

## âœ¨ Features Implemented

### 1. Upload & Parsing
- Drag-and-drop PDF upload interface
- Real-time parsing status with page count
- Error handling and retry capability
- File validation (PDF only, max 50MB)

### 2. Status Tracking
- Parse status indicator (success/failed/pending)
- Number of pages extracted
- Parsed timestamp
- Error messages with details
- Refresh capability

### 3. Mock Criteria Display
- 4 pre-configured test criteria based on LM5145 and TL07xx datasheets:
  - Gain at nominal input (30% weight, dB, higher is better)
  - Output voltage accuracy (20% weight, %, higher is better)
  - Thermal performance (25% weight, Â°C rise, lower is better)
  - Power consumption (25% weight, W, lower is better)

### 4. AI Assistant Panel
- Question input with multi-line support
- Criterion selector dropdown (optional focus)
- Suggested questions as clickable chips
- AI-powered Q&A with datasheet context
- Citation display with page numbers and snippets
- Confidence scoring visualization
- "Not found" detection and highlighting

### 5. Citations Display
- Page number badges
- Exact text snippets from datasheet
- Copy-to-clipboard functionality
- Visual indication of source reliability
- Warning when no citations provided

### 6. Suggested Rating Card
- AI-generated component ratings
- Score visualization (0-10 scale)
- Color-coded performance indicators
- Detailed reasoning and rationale
- Supporting citations
- Confidence score display

## ðŸ—ï¸ Component Architecture

### Created Components

```
frontend/src/components/
â”œâ”€â”€ DatasheetUploadCard.tsx          # Upload interface
â”œâ”€â”€ DatasheetStatusCard.tsx          # Status display
â”œâ”€â”€ TradeStudyCriteriaPreviewCard.tsx # Mock criteria
â”œâ”€â”€ DatasheetCitationsList.tsx       # Citation rendering
â”œâ”€â”€ DatasheetSuggestedRatingCard.tsx # Rating display
â””â”€â”€ DatasheetAssistantPanel.tsx      # Main Q&A interface

frontend/src/pages/
â””â”€â”€ DatasheetLab.tsx                 # Complete test bench page
```

### Component Hierarchy

```
DatasheetLab
â”œâ”€â”€ Header (with branding and description)
â”œâ”€â”€ Alert Banner (test environment warning)
â””â”€â”€ Main Content (2-column layout)
    â”œâ”€â”€ Left Column (30-35%)
    â”‚   â”œâ”€â”€ DatasheetUploadCard
    â”‚   â”œâ”€â”€ DatasheetStatusCard
    â”‚   â””â”€â”€ TradeStudyCriteriaPreviewCard
    â””â”€â”€ Right Column (65-70%)
        â””â”€â”€ DatasheetAssistantPanel
            â”œâ”€â”€ Suggested Questions
            â”œâ”€â”€ Q&A Input Form
            â”œâ”€â”€ Answer Display
            â”œâ”€â”€ DatasheetCitationsList
            â””â”€â”€ DatasheetSuggestedRatingCard
```

## ðŸ”Œ API Integration

The test bench uses these backend endpoints:

### 1. Upload & Parse
```
POST /api/components/{test-component-id}/datasheet
Content-Type: multipart/form-data

Body: { file: PDF }
```

### 2. Get Status
```
GET /api/components/{test-component-id}/datasheet/status

Response:
{
  "has_datasheet": true,
  "parsed": true,
  "num_pages": 12,
  "parsed_at": "2024-01-15T10:30:00Z",
  "parse_status": "success",
  "parse_error": null
}
```

### 3. Query Datasheet
```
POST /api/components/{test-component-id}/datasheet/query
Content-Type: application/json

Body:
{
  "question": "What is the input voltage range?",
  "criterion_id": "optional-criterion-id"
}

Response:
{
  "answer": "The input voltage range is 6-75V...",
  "citations": [
    {
      "page_number": 6,
      "snippet": "VIN operating input voltage range: 6â€“75 V"
    }
  ],
  "confidence": 0.85,
  "rating": {  // Optional, if backend implements
    "criterion": "Output voltage accuracy",
    "score": 8.5,
    "max_score": 10,
    "rationale": "Based on specifications in Section 7.5...",
    "citations": [...],
    "confidence": 0.8
  }
}
```

### 4. Get Suggestions
```
GET /api/components/{test-component-id}/datasheet/suggestions

Response:
{
  "suggestions": [
    "What is the gain in dB?",
    "What is the power consumption in W?",
    "What is the operating frequency range in GHz?",
    ...
  ]
}
```

## ðŸ§ª Testing Instructions

### Quick Test Flow

1. **Navigate to Lab**
   - Click "Datasheet AI Lab" in sidebar
   - Or go to `/datasheet-lab`

2. **Upload Test Datasheet**
   - Drag-and-drop or select a PDF
   - Recommended: LM5145 or TL07xx datasheets
   - Wait for parsing (watch status card)

3. **Try Suggested Questions**
   - Click any suggested question chip
   - Or type your own question

4. **Review Results**
   - Check answer text
   - Verify citations are present
   - Review confidence score
   - Examine suggested rating (if available)

5. **Test Anti-Hallucination**
   - Ask about a value that doesn't exist
   - Verify AI responds "Not found in datasheet"
   - Confirm no invented values

### Sample Test Questions

For **LM5145** (voltage mode controller):
- "What is the input voltage range?"
- "What is the thermal shutdown temperature?"
- "What is the switching frequency range?"
- "What is the maximum duty cycle?"

For **TL07xx** (op-amp):
- "What is the slew rate?"
- "What is the input voltage range?"
- "What is the typical gain bandwidth product?"
- "What is the supply current?"

### Anti-Hallucination Tests

Try these questions (should return "not found"):
- "What is the quantum efficiency?" (not in these datasheets)
- "What is the bluetooth range?" (not relevant)
- "What is the tensile strength?" (wrong domain)

## ðŸŽ¨ UI/UX Features

### Visual Indicators

- **Parse Status**:
  - ðŸŸ¢ Green checkmark: Success
  - ðŸ”´ Red X: Failed
  - ðŸŸ¡ Yellow spinner: In progress

- **Confidence Scores**:
  - Green bar: > 70% confidence
  - Yellow bar: 40-70% confidence
  - Red bar: < 40% confidence

- **Rating Scores**:
  - Green: â‰¥ 80% of maximum
  - Yellow: 60-79%
  - Orange: 40-59%
  - Red: < 40%

### Interactive Elements

- **Suggested Questions**: Click to auto-fill
- **Citations**: Click "Copy" to copy snippet
- **Status**: Click "Refresh" to update
- **Upload**: Drag-and-drop or click to browse

## ðŸ”§ Technical Details

### Test Component ID
```typescript
const TEST_COMPONENT_ID = 'test-datasheet-lab-component';
```

This is a special component ID used exclusively for the test bench. It doesn't interfere with production components.

### Mock Criteria Structure
```typescript
export interface MockCriterion {
  id: string;
  name: string;
  weight: number;
  unit: string;
  higherIsBetter: boolean;
}
```

### State Management

The DatasheetLab page manages:
- `refreshTrigger`: Counter to trigger status refresh
- `datasheetParsed`: Boolean to enable/disable AI panel

Components are loosely coupled via props and callbacks.

## ðŸš€ Deployment & Testing

### Local Development

1. **Start Backend**:
   ```bash
   cd backend
   uvicorn app.main:app --reload
   ```

2. **Start Frontend**:
   ```bash
   cd frontend
   npm start
   ```

3. **Navigate to Lab**:
   ```
   http://localhost:3000/datasheet-lab
   ```

### Production Considerations

- Test component is isolated (won't affect real data)
- All uploads use the same test component ID
- Mock criteria are hardcoded (easy to update)
- No persistence required (refresh resets state)

## ðŸ“‹ Acceptance Criteria âœ…

All PRD requirements met:

âœ… **Upload & Parse**: PDF upload triggers parsing, shows page count  
âœ… **Status Display**: Shows parsed/failed/pending with details  
âœ… **Q&A Interface**: Engineers can ask questions and receive answers  
âœ… **Citations**: All answers include page numbers and snippets  
âœ… **Suggested Rating**: AI generates ratings with reasoning (stub-ready)  
âœ… **Anti-Hallucination**: "Not found" detection and highlighting  
âœ… **Beautiful UI**: Matches TradeForm theme and branding  
âœ… **Isolated**: Doesn't affect production projects/components  

## ðŸŽ¯ Use Cases

### 1. Feature Validation
- Test datasheet parsing accuracy
- Verify AI query correctness
- Validate citation extraction
- Check anti-hallucination mechanisms

### 2. Demo & Presentations
- Show datasheet capabilities to stakeholders
- Demonstrate AI-powered analysis
- Highlight citation reliability
- Prove no hallucinations

### 3. Development Testing
- Test new AI prompt changes
- Validate backend modifications
- Debug parsing issues
- Experiment with queries

### 4. User Training
- Teach engineers how to ask questions
- Show best practices for queries
- Demonstrate citation usage
- Train on confidence interpretation

## ðŸ”® Future Enhancements

Possible improvements (not currently implemented):

1. **Multiple Test Components**: Support multiple test uploads
2. **Datasheet Comparison**: Side-by-side comparison mode
3. **Export Results**: Save Q&A sessions as reports
4. **Query History**: Track previous questions
5. **Advanced Filters**: Filter suggestions by criterion
6. **PDF Viewer**: Inline PDF display with highlights
7. **Batch Questions**: Ask multiple questions at once
8. **Real-Time AI**: Streaming responses

## ðŸ“ File Summary

### New Files Created (9)

**Components (6)**:
- `DatasheetUploadCard.tsx` - 215 lines
- `DatasheetStatusCard.tsx` - 140 lines
- `TradeStudyCriteriaPreviewCard.tsx` - 120 lines
- `DatasheetCitationsList.tsx` - 110 lines
- `DatasheetSuggestedRatingCard.tsx` - 185 lines
- `DatasheetAssistantPanel.tsx` - 285 lines

**Pages (1)**:
- `DatasheetLab.tsx` - 260 lines

**Documentation (2)**:
- `DATASHEET_LAB_GUIDE.md` - This file
- Previous guides still apply

### Modified Files (2)

- `App.tsx` - Added route for `/datasheet-lab`
- `Layout.tsx` - Added navigation item with "Lab" badge

**Total New Code**: ~1,500+ lines

## ðŸ†˜ Troubleshooting

### Upload Fails
- âœ“ Check file is PDF
- âœ“ Verify file size < 50MB
- âœ“ Ensure backend is running
- âœ“ Check console for errors

### No Suggestions
- âœ“ Verify datasheet parsed successfully
- âœ“ Check backend AI stub is configured
- âœ“ Refresh page and try again

### No Citations
- âœ“ Yellow warning will display
- âœ“ Try rephrasing question
- âœ“ Ask for specific parameters
- âœ“ Check if value exists in datasheet

### Status Stuck on "Pending"
- âœ“ Check backend logs for parsing errors
- âœ“ Verify pdfplumber is installed
- âœ“ Try re-uploading file
- âœ“ Click "Refresh Status"

## ðŸŽ“ Best Practices

### For Testing

1. **Use Real Datasheets**: LM5145, TL07xx, or similar
2. **Test Edge Cases**: Missing values, complex tables
3. **Verify Citations**: Cross-check with actual PDF
4. **Try Various Criteria**: Test all 4 mock criteria
5. **Check Confidence**: Note when confidence is low

### For Questions

1. **Be Specific**: "What is the gain at 8.2 GHz?" vs "What is the gain?"
2. **Include Units**: "What is the voltage in V?" helps context
3. **Reference Sections**: "What is the thermal data?" 
4. **Use Criterion Focus**: Select relevant criterion for better context
5. **Iterate**: Rephrase if first answer isn't satisfactory

## ðŸ“Š Success Metrics

Monitor these during testing:

- âœ… Parse success rate (should be high for valid PDFs)
- âœ… Citation accuracy (all answers should have citations)
- âœ… Hallucination rate (should be 0% for missing values)
- âœ… Confidence correlation (high confidence = accurate answers)
- âœ… User satisfaction (queries answered correctly)

---

**Status**: âœ… Fully Implemented  
**Production Ready**: âœ… Yes (as test environment)  
**Documentation**: âœ… Complete  
**Testing**: Ready for validation  

**Access URL**: http://localhost:3000/datasheet-lab ðŸš€

